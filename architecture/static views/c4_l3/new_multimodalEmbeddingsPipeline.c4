model {

    extend multimodalEmbeddingsPipeline {
        container orchestrator {
            description "Orchestrates the multimodal embeddings pipeline"
            technology "Python, Ray or similar"
        }
        container formatConvertor {
            description "Converts input files to a common format (PDF)"
            technology "Python, Pillow and img2pdf or similar"
        }
        container textExtractor {
            description "Extracts text from binary input files (PDF)"
            technology "Python, PyMuPDF or pdfplumber or similar"
        }
        container imagesExtractor {
            description "Extracts images from binary input files (PDF)"
            technology "Python, PyMuPDF or pdf2image or similar"
        }
        container textPreprocessor {
            description "Preprocesses text input (aptitude test short questions and answers, case study): removes unnecessary characters, normalizes whitespace, and tokenizes into segments"
            technology "Python, NLTK or spacy or similar"
        }
        container imagePreprocessor {
            description "Preprocesses image input (case study): resizes, normalizes, and converts to grayscale"
            technology "Python, OpenCV or Pillow or similar"
        }
        container textTokenizer {
            description "Converts aptitude test short questions answers into numerical tokens"
            technology "Python, BertTokenizer from Hugging Face Transformers Tokenizers or similar"
        }
        container textEmbeddingsGenerator {
            description "Generates embeddings from tokenized short questions answers"
            technology "Python, BertModel from Hugging Face Transformers or similar"
        }
        container imageEmbeddingsGenerator {
            description "Generates embeddings from preprocessed images"
            technology "Python, CLIPModel or ViTModel from Hugging Face Transformers or similar"
        }
        container embeddingsStore {
            description "Stores embeddings of valid short questions answers"
            technology "Weviate or Pinecone or similar"
            style {
                shape cylinder
            }
        }
    }

    multimodalEmbeddingsPipeline.orchestrator -> multimodalEmbeddingsPipeline.formatConvertor "converts input files to a common format (PDF)" {
        style {
            color green
        }
    }
    multimodalEmbeddingsPipeline.orchestrator -> multimodalEmbeddingsPipeline.textExtractor "extracts text from binary input files (PDF)" {
        style {
            color green
        }
    }
    multimodalEmbeddingsPipeline.orchestrator -> multimodalEmbeddingsPipeline.imagesExtractor "extracts images from binary input files (PDF)" {
        style {
            color green
        }
    }
    multimodalEmbeddingsPipeline.textExtractor -> multimodalEmbeddingsPipeline.textPreprocessor "preprocesses text input (text of aptitude test or case study)" {
        style {
            color green
        }
    }
    multimodalEmbeddingsPipeline.imagesExtractor -> multimodalEmbeddingsPipeline.imagePreprocessor "preprocesses image input (images from aptitude test or case study)" {
        style {
            color green
        }
    }
    multimodalEmbeddingsPipeline.textPreprocessor -> multimodalEmbeddingsPipeline.textTokenizer "tokenizes text of aptitude test or case study" {
        style {
            color green
        }
    }
    multimodalEmbeddingsPipeline.textTokenizer -> multimodalEmbeddingsPipeline.textEmbeddingsGenerator "generates embeddings from tokenized text of aptitude test or case study" {
        style {
            color green
        }
    }
    multimodalEmbeddingsPipeline.imagePreprocessor -> multimodalEmbeddingsPipeline.imageEmbeddingsGenerator "generates embeddings from preprocessed images" {
        style {
            color green
        }
    }
    multimodalEmbeddingsPipeline.textEmbeddingsGenerator -> multimodalEmbeddingsPipeline.embeddingsStore "stores embeddings of tokenized text of aptitude test or case study" {
        style {
            color green
        }
    }
    multimodalEmbeddingsPipeline.imageEmbeddingsGenerator -> multimodalEmbeddingsPipeline.embeddingsStore "stores embeddings of preprocessed images from aptitude test or case study" {
        style {
            color green
        }
    }
}

views {
    
    // Shared local styles
    style element.kind != actor {
        notation "C4 Containers - unchanged"
    }
    style multimodalEmbeddingsPipeline.orchestrator, multimodalEmbeddingsPipeline.textExtractor, multimodalEmbeddingsPipeline.imagesExtractor, multimodalEmbeddingsPipeline.textPreprocessor, multimodalEmbeddingsPipeline.imagePreprocessor, multimodalEmbeddingsPipeline.textTokenizer, multimodalEmbeddingsPipeline.textEmbeddingsGenerator, multimodalEmbeddingsPipeline.imageEmbeddingsGenerator, multimodalEmbeddingsPipeline.embeddingsStore, multimodalEmbeddingsPipeline.formatConvertor {
        notation "C4 Containers - added for AI extension"
        color green
    }

    view multimodalEmbeddingsPipelineContainer of multimodalEmbeddingsPipeline {
        title "Container view (C4 L2) of Multimodal Embeddings Pipeline"

        include multimodalEmbeddingsPipeline.orchestrator
        include multimodalEmbeddingsPipeline.formatConvertor
        group "Text processing" {
            include multimodalEmbeddingsPipeline.textExtractor
            include multimodalEmbeddingsPipeline.textPreprocessor
            include multimodalEmbeddingsPipeline.textTokenizer
            include multimodalEmbeddingsPipeline.textEmbeddingsGenerator
        }
        group "Images processing" {
            include multimodalEmbeddingsPipeline.imagesExtractor
            include multimodalEmbeddingsPipeline.imagePreprocessor
            include multimodalEmbeddingsPipeline.imageEmbeddingsGenerator
        }
        group "Persistent Storage" {
            include multimodalEmbeddingsPipeline.embeddingsStore
        }
    }
}